---
title: "Operating System - Process(2)"
date: 2020-07-29
last_modified_at: 2020-07-29
desc: "OS 프로세스(2)"
keywords: "OS,Operating System,Process,프로세스"
permalink: "/os/process2"
categories: 
    - OS
tags: 
    - OS
    - Process
---

## 프로세스 간 통신

운영체제 내에서 실행되는 병행 프로세스들은 독립적이거나 협력적이다. 프로세스가 시스템에서 실행 중인 다른 프로세스들과 데이터를 공유하지 않으면 그 프로세스는 **독립적**이다. 그와 반대로 프로세스가 시스템에서 실행 중인 다른 프로세스들에 영향을 주거나 받는다면 이는 **협력적**인 프로세스이다. 프로세느 협력을 허용하는 환경을 제공하는 데는 몇 가지 이유가 있다.

* 정보 공유 - 여러 응용 프로그램이 동일한 정보에 흥미를 느낄 수 있으므로, 그러한 정보를 병행적으로 접근할 수 있는 환경을 제공해야 한다.
* 계산 가속화 - 만일 특정 태스크를 빨리 실행하고자 한다면, 그 태스크를 서브태스크로 나누어 이들 각각 다른 서브태스크들과 병령로 실행되게 해야 한다. 이러한 가속화는 복수 개의 프로세서를 가진 경우에만 달성할 수 있음을 유의하라
* 모듈성 - 시스템 기능을 별도의 프로세스 또는 스레드로 나누어, 모듈식 형태의 시스템을 구성할 수 있다.

협력적 프로세스들은 데이터를 교환할 수 있는, 즉 서로 데이터를 보내거나 받을 수 있는 프로세스 간 통신(interprocess communication) 기법이 필요하다. 프로세스 간 통신에는 기본적으로 **공유 메모리**와 **메시지 전달**의 두 가지 모델이 있다. 공유 메모리 모델에서는 협력 프로세스들에 의해 공유 되는 메모리의 영역이 구축된다. 프로세스들은 그 영역에 데이터를 읽고 쓰고 함으로써 정보를 교환할 수 있다. 메시지 전달 모델에서는 통신이 협력 프로세스들 사이에 교환되는 메시지를 통하여 이루어진다. 이 두 모델은 아래 이미지와 같다.

![imageProcess]({{ site.url }}{{ site.baseurl }}/assets/images/posts/image_os_ipc_2_model.png)

언급된 두 모델은 운영체제에서 많은 시스템이 두 가지를 모두 구현한다. 메시지 전달 모델은 충돌을 회피할 필요가 없기 때문에 적은 양의 데이터를 교환 하는 데 유용하다. 메시지 전달은 __분산 시스템__ 에서 공유 메모리보다 구현하기 쉬우며, 메시지 전달 시스템은 통상 시스템 콜을 사용하여 구현되므로 커널 간섭 등의 부가적인 시간 소비 작업이 필요하기 때문에 공유 메모리 모델보다 느리다. 공유 메모리 시스템에서는 공유 메모리 영역을 구축할 때만 시스템 콜이 필요하다. 공유 메모리 영역이 구축되면 모든 접근은 일반적인 메모리 접근으로 취급되어 커널의 도움이 필요 없다.

### 공유 메모리 시스템에서의 프로세스간 통신

공유 메모리를 사용하는 프로세스 간 통신에서는 통신하는 프로세스들이 공유 메모리 영역을 구축해야 한다. 통상 공유 메모리 영역은 공유 메모리 세그먼트 생성하는 프로세스의 주소 공간에 위치한다. 이 공유 메모리 세그먼트를 이용하여 통신하고자 하는 다른 프로세스들은 이 세그먼트를 자신의 주소 공간에 추가해야 한다. 일반적으로 운영체제는 한 프로세스가 다른 프로세스의 메모리에 접근하는 것을 금지하며, 공유 메모리는 둘 이상의 프로세스가 이 제약 조건을 제거하는 것에 동의하는 것을 필요로 한다. 그런 후 프로세스들은 공유 영역에 읽고 씀으로써 정보를 교환할 수 있다. 데이터의 형식과 위치는 이들 프로세스에 의해 결정되며 운영체제의 소관이 아니다. 또한 프로세스들은 동시에 동일한 위치에 쓰지 않도록 서로 책임져야 한다.

협력하는 프로세스의 개념을 설명하기 위해서 협력하는 프로세스의 일반적인 패러다임인 **생상자 - 소비자** 문제를 생각해 보기로 하자. **생산자** 프로세스는 정보를 생산하고 **소비자** 프로세스는 정보를 소비한다. 예를 들어, 컴파일러는 어셈블리 코드를 생산하고, 어셈블러는 생산한 어셈블리 코드를 소비한다. 어셈블러는 이어 목적 모듈을 생산할 수 있고, 로더는 이들을 소비한다. 일반적으로 우리는 서버를 **생산자**로 클라이언트를 **소비자**로 생각한다. 예를 들면 웹 서버는 HTML 파일과 이미지와 같은 웹 콘텐츠를 생산하고 이 자원들을 요청한 클라이언트 웹 브라우저가 소비하게 된다.

생산자 - 소비자 문제의 하나의 해결책은 공유 메모리를 사용하는 것이다. 생산자와 소비자 프로세스들이 병행으로 실행되도록 하려면, 생산자가 정보를 채워 넣고 소비자가 소모할 수 있는 항목들의 버퍼가 반드시 사용 가능해야 한다. 이 버퍼는 생산자와 소비자가 공유하는 메모리 영역에 존재하게 된다. 생산자가 한 항목을 생산하고, 그 동안 소비자는 다른 항목을 소비할 수 있다. 생산자와 소비자가 반드시 동기화 되어야 생상되지도 않는 항목들을 소비자가 소비하려고 시도하지 않을 것이다.

이때 두 가지 유형의 버퍼가 사용된다. 무한 버퍼의 생산자 소비자 문제에서는 버퍼의 크기에 실질적인 제한이 없다. 소비자는 새로운 항목을 기다려야 할 수도 있지만, 생산자는 항상 새로운 항목을 생산할 수 있다. 유한 버퍼는 버퍼의 크기가 고정되어 있다고 가정한다. 이 경우 버퍼가 비어 있으면 소비자는 반드시 대기해야 하며, 모든 버퍼가 채워져 있으면 생산자가 대기해야 한다.

유한 버퍼가 공유 메모리를 사용한 프로세스간 통신을 어떻게 분명하게 하는지 살펴보자. 다음 변수들은 생산자와 소비자 프로세스가 공유하는 메모리 영역에 존재한다.

```C
#define BUFFER_SIZE 10

typedef struct {
    ...
} item;

item buffer[BUFFER_SIZE]
int in = 0;
int out = 0;
```

공유 버퍼는 두 개의 논리 포인터 in과 out을 갖는 원형 배열로 구현된다. 변수 in은 버퍼 내에서 다음으로 비어 있는 위치를 가르키며, out은 버퍼 내에서 첫 번째로 채워져 있는 위치를 가리킨다. in == out; 일 때 버퍼는 비어있고 (((in + 1) % BUFFER_SIZE) == out) 이면 버퍼는 가득 차 있다. 생산자와 소비자의 코드가 아래의 그림에 각각 나와 있다. 생산자 프로세스는 next_produced 라는 지역 변수에 다음번 생산되는 item을 저장하고 있다. 소비자 코드는 next_consumed 라는 지역 변수에 다음번 소비되는 item을 저장하고 있다.

```C
item next_produced;

while (true) {
    /* produce an item in next_produced */

    while (((in + 1) % BUFFER_SIZE) == out)
        ;/* do nothing */

    buffer[in] = next_produced;
    in = (in + 1) % BUFFER_SIZE
}
```

```C
item next_consumed;

while (true) {
    while (in == out)
        ; /* do nothing */

    next_consumed = buffer[out];
    out = (out + 1) % BUFFER_SIZE;

    /* consume the item in next_consumed */
}

```

### 메시지 전달 시스템에서 프로스세 간 통신

메시지 전달 방식은 동일한 주소 공간을 공유하지 않고도 프로세스들이 통신 하고, 그들의 동작을 동기화할 수 있도록 허용하는 기법을 제공한다. 메시지 전달 방식은 통신하는 프로세스들이 네트워크에 의해 연결된 다른 컴퓨터들에 존재할 수 있는 분산 환경에서 특히 유용하다. 한 예로 WWW에 사용되는 chat 프로그램은 서로 메시지를 교환하여 통신하도록 설계될 수 있다.

메시지 전달 시스템은 최소한 두 가지 연산을 제공한다.

* send(message)
* receive(message)

프로세스가 보낸 메시지는 고정 길이일 수도 있고 가변 길이일 수도 있다. 고정 길이 메시지만 보낼 수 있다면, 시스템 수준의 구현은 직선적이다. 그렇지만, 이러한 제한은 프로그래밍 작업을 더욱 힘들게 한다. 반면에, 가변 길이 메시지는 보다 복잡한 시스템 수준의 구현이 있어야 하지만, 프로그래밍 작업은 더 간단해진다. 이러한 일은 운영체제 설계 전반에 걸쳐 흔히 볼 수 있는 교환이다.

만약 프로세스 P와 Q가 통신을 원하면, 반드시 서로 메시지를 보내고 받아야 한다. 이들 사이에 통신 연결이 설정되어 있어야한다. 이 연결은 다양한 방법으로 구현할 수 있다. 여기서 알아볼 것은 물리적인 구현이 아니라 논리적인 구현이다. 하나의 링크와 send()/receive() 연산을 논리적으로 구현하는 다수의 방법은 아래와 같다.

* 직접 또는 간접 통신
* 동기식 또는 비동기식 통신
* 자동 또는 명시적 버퍼링

### 네이밍

통신을 원하는 프로세스들은 서로를 가리킬 방법이 있어야 한다. 이들은 간접 통신 또는 직접 통신을 사용할 수 있다. **직접 통신**에서 통신을 원하는 각 프로세스는 통신의 수신자 또는 송신자의 이름을 명시해야 한다. 이 기법에서 send(), receive() 함수들은 다음과 같이 정의해야 한다.

* send(P, message) - 프로세스 P에 메시지를 전송한다.
* receive(Q, message) - 프로세스 Q로부터 메시지를 수신한다.

이 기법의 통신 연결은 다음의 특성을 가진다.

* 통신을 원하는 각 프로세스의 쌍들 사이에 연결이 자동으로 구축된다. 프로세스들은 통신하기 위해 상대방의 id만 알면 된다.
* 연결은 정확히 두 프로세스 사이에만 연관된다.
* 통신하는 프로세스들의 각 쌍 사이에는 정확하게 하나의 연결이 존재해야 한다.

이 기법은 주소 방식에서 대칭성을 보인다. 즉, 송신자와 수신자 프로세스 모두 통신하려면 상대방의 이름을 제시해야 한다. 이 기법의 변형으로는 주소 지정 시에 비대칭이 있다. __송신자만 수신자 이름을 지명하며, 수신자는 송신자의 이름을 제시할 필요가 없다.__ 이 기법에서 send()와 receive() 함수들은 다음과 같이 정의한다.

* send(P, message) - 메시지를 프로세스 P에 전송한다.
* receive(id, message) - 임의의 프로세스로 부터 메시지를 수신한다. 변수 id는 통신을 발생시킨 프로세스의 이름으로 설정된다.

이들 기법 모두 프로세스를 지정하는 방식 때문에 모듈성을 제한한다는 것이 단점이다. 프로세스의 이름을 바꾸면 모든 다른 프로세스 지정 부분을 검사할 필요가 있을 수 있다. 옛 이름들에 대한 모든 참조를 찾아서 새로운 이름으로 변경해야 할 것이다. 일반적으로 이러한 하드코딩 기법은, 이 상황에서 id를 명시적으로 표시해야 한다. 다음에 설명할 간접적인 방식에 비해 바람직하지 않다.

**간접 통신**에서 메시지들은 **메일박스** 또는 **포트**로 송신되고, 수신된다. 메일박스는 추상적으로 프로세스들에 의해 메시지들이 넣어지고, 메시지들이 제거될 수 있는 객체로 볼 수 있다. 각 메일박스는 고유의 id를 가진다. 예를 들어 POSIX 메시지 큐는 메일박스를 식별하기 위하여 정수 값을 사용한다. 이 기법에서 프로세스는 다수의 상이한 메일박스를 통해 다른 프로세스들과 통신할 수 있다. 두 프로세스들이 공유 메일박스를 가질 때만 이들 프로세스가 통신할 수 있다. send()와 receive() 함수들은 다음과 같이 정의할 수 있다.

* send(A, message) - 메시지를 메일박스 A로 전송한다.
* receive(A, message) - 메시지를 메일박스 A로부터 수신한다.

이 방법에서 통신 연결은 다음의 성질을 가진다.

* 한 쌍의 프로세스들 사이의 연결은 이들 프로세스가 공유 메일박스를 가질 때만 구축된다.
* 연결은 두 개 이상의 프로세스들과 연관될 수 있다.
* 통신하고 있는 각 프로세스 사이에는 다수의 서로 다른 연결이 존재할 수 있고, 각 연결은 하나의 메일박스에 대응된다.

프로세스 P1, P2, P3가 모두 메일박스 A를 공유한다고 가정하자. 프로세스 P1은 메시지를 A에 송신하고, P2, P3는 각각 A로부터 receive()를 실행한다. 어느 프로세스가 P1이 보낸 메시지를 수신하는가? 이 문제에 대한 답은 앞으로 선택할 기법에 좌우된다.

* 하나의 링크는 최대 두 개의 프로세스와 연관되도록 허용한다.
* 한 순간에 하나의 프로세스가 receive() 연산을 실행하도록 허용한다.
* 어느 프로세스가 메시지를 수신할 것인지 시스템이 임의로 선택하도록 한다. 시스템이 어느 프로세스가 수신할 것인지를 선택하는 알고리즘을 정의할 수 있다. 시스템은 송신자에게 수신자를 알려 줄 수 있다.

메일박스는 한 프로세스 또는 운영체제에 의해 소유될 수 있다. 메일박스가 한 프로세스에 의해 소유된다면, 각 메일박스가 고유한 소유자를 가지고 있기 때문에, 소유자와 메일박스의 사용자를 구분할 수 있다. 그러므로 __이 메일박스로 보내진 메시지를 어느 프로세스가 수신할지에 대한 혼란이 있을 수 없다.__ 메일박스를 소유하고 있는 프로세스가 종료될 때, 메일박스는 사라진다. 그 후 이 메일박스로 메시지를 송신하는 모든 프로세스는 더는 메일박스가 존재하지 않는다는 사실을 반드시 통보받아야 한다.

반면에, 운영체제가 소유한 메일박스는 자체적으로 존재한다. 이것은 독립적인 것으로 어떤 특정한 프로세스에 포함되지 않는다. 운영체제는 한 프로세스에 아래의 액션을 할 수 있도록 허용하는 기법을 반드시 제공해야 한다.

* 새로운 메일박스를 생성한다.
* 메일박스를 통해 메시지를 송신하고 수신한다.
* 메일박스를 생성한다.

새로운 메일박스를 생성하는 프로세스는 디폴트로 메일박스의 소유자가 된다. 초기에는, 소유자만이 이 메일박스를 통해 메시지를 수신할 수 있는 유일한 프로세스이다. 그러나 소유권과 수신권은 적절한 시스템 콜을 통해 다른 프로세스에 전달될 수 있다. 

> 물론 이런 규칙으로 인해 메일박스마다 복수의 수신자를 낳을 수 있다.

### 동기화

프로세스 간 통신은 send와 receive 함수 호출에 의해 발생한다. 각 함수를 구현하기 위한 서로 다른 설계 옵션이 있다. 메시지 전달은 블록킹이거나 논블록킹 방식으로 전달된다. 이 두 방식은 각각 동기식, 비동기식이라고도 알려져 있다.

* 블록킹 전송 - 송신하는 프로세스는 메시지가 수신 프로세스 또는 메일박스에 의해 수신될 때까지 블록된다.
* 논블록킹 전송 - 송신하는 프로세스가 메시지를 보내고 작업을 재시작한다.
* 블록킹 수신 - 메시지가 이용 가능할 때까지 수신 프로세스가 블록된다.
* 논블록킹 수신 - 송신하는 프로세스가 유효한 메시지 또는 null을 받는다.

send()와 receive()의 다른 조합도 가능하다. send()와 receive()가 모두 블록킹일 때, 우리는 송신자와 수신자 간의 랑데부를 하게 된다. 블록킹 send()와 receive()를 사용한다면 생산자와 소비자 문제에 대한 해결책은 사소한 문제가 된다. 생산자는 단순히 블록킹 send()를 호출하고 메시지가 수신자 또는 메일박스에 전달될 때까지 기다린다. 유사하게 소비자가 receive()를 호출하면 메시지가 전달될 때까지 블록된다. 

```C
message next_produced;

while(true) {
    /* produce an item in next_produced */

    send(next_produced)
}
```

```C
message next_consumed;

while (true) {
    receive(next_consumed)

    /* consume the item in next_consumed */
}
```

### 버퍼링

통신이 직접적이든 간접적이든 간에, __통신하는 프로세스들에 의해 교환되는 메시지는 임시 큐에 들어 있다.__ 기본적으로 이러한 큐를 구현하는 방식은 세 가지가 있다.

* 무용량 - 큐의 최대 길이가 0이다. 즉, 메시지를 저장할 공간이 없으므로 이 경우에, **송신자는 수신자가 메시지를 수신할 때까지 기다려야 한다.**

* 유한 용량 - 큐는 유한한 길이 n을 가진다. 즉, 최대 n개의 메시지가 그 안에 들어 있을 수 있다. 새로운 메시지가 전송될 때 큐가 꽉 찬 것이 아니라면, 메시지는 큐에 놓이며, 송신자는 대기하지 않고 실행을 계속한다. 하지만 큐가 꽉 차게 되면, 송신자는 큐 안의 공간이 이용 가능할 때까지 반드시 블록되어야 한다.

* 무한 용량 - 큐는 잠재적으로 무한한 길이를 가진다. 따라서 메시지들이 얼마든지 큐 안에 대기할 수 있다. 송신자는 절대 블록되지 않는다.

> 무용량의 경우 때때로 버퍼가 없는 메시지 시스템 이라고 불린다. 다른 경우는 자동 버퍼링이라 불린다.

### POSIX 공유 메모리

공유 메모리와 메시지 전달을 포함하여 POSIX 시스템을 위한 다수의 IPC 기법이 사용 가능하다. 여기서 공유 메모리를 위한 POSIX API를 살펴보자.

POSIX 공유 메모리는 메모리 - 맵핑 파일을 사용하여 구현된다. 메모리 - 맵핑 파일은 공유 메모리의 특정 영역을 파일과 연관시킨다. 프로세스는 먼저 아래와 같으 __shm_open()__ 시스템 콜을 사용하여 공유 메모리 객체를 생성해야 한다.

```c
fd = shm_open(name, O_CREATE | O_RDWR, 0666);
```

첫 번째 인자는 공유 메모리 객체의 이름을 지정한다. 공유 메모리에 접근하고자 하는 프로세스는 이 이름을 통하여 객체를 언급한다. 두 번째 인자는 객체가 존재하지 않으면 생성되고 객체는 읽기와 쓰기가 가능한 상태로 열린다는것을 나타낸다. 마지막 인자는 공유 메모리 객체에 파일 - 접근 허가권을 부여한다. shm_open() 시스템 콜이 성공하면 공유 메모리 객체를 나타내는 정수형 파일 설명자를 반환한다.

객체가 설정되면 __ftruncate()__ 함수를 사용하여 객체의 크기를 바이트 단위로 설정한다. 다음과 같은 호출은 객체의 크기를 4096바이트로 설정한다

```c
ftruncate(fd, 4096)
```

마지막으로 __mmap()__ 함수가 공유 메모리 객체를 포함하는 메모리 - 맵핑 파일을 구축한다. mmap() 함수는 공유 메모리 객체에 접근할 때 사용될 메모리 - 맵핑 파일의 포인터를 반환한다.

> 여기서 예제는 생성자 소비자 모델을 사용한다. 생성자는 공유 메모리 객체를 구축하고, 공유 메모리에 데이터를 쓰며 소비자는 공유 메모리에서 데이터를 읽는다.

아래의 예제는 OS라고 명명된 공유 메모리 객체를 생성하고 문자열 "Hello World!"를 공유 메모리에 쓴다. 프로그램은 지정된 크기의 공유 메모리 객체를 메모리에 맵핑하고 객체에 쓰기 권한을 부여한다. MAP_SHARED 플래그는 공유 메모리 객체에 변경이 발생하면 객체를 공유하는 모든 프로세스가 최신의 값을 접근하게 된다는 것을 지정한다. 공유 메모리 객체에 쓰기 작업을 할 때 sprintf() 함수를 호출하고 출력 형식이 완성된 문자열은 ptr이 가리키는 공유 메모리 객체에 쓰인다는것을 주의하라. 쓰기 작업이 성공하면 쓰인 바이트 수만큼 포인터를 반드시 증가시켜야 한다.

```c

/* include groups */

int main() {
    const int SIZE = 4096;
    const char *name = "OS";
    const char *message_0 = "Hello";
    const char *message_1 = "World!";

    int fd;
    char *ptr;

    fd = shm_open(name, O_CREATE | O_RDWR, 0666);

    ftruncate(fd, SIZE);

    ptr = (char *) mmap(0, SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);

    sprintf(ptr, "%s", message_0)
    ptr += strlen(message_0)
    sprintf(ptr, "%s", message_1)
    ptr += strlen(message_1)

    return 0
}

```

아래의 예제 소비자 프로세스는 공유 메모리의 내용을 읽고 출력한다. 또한 소비자는 __shm_unlink()__ 함수를 호출하여 접근이 끝난 공유 메모리를 제거한다.

```c

/* include groups */

int main() {
    const int SIZE = 4096;
    const char *name = "OS";
    
    int fd;
    char *ptr;

    fd = shm_open(name, O_RDONLY, 0666);

    ptr = (char *) mmap(0, SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0)

    printf("%s", (char *)ptr)

    shm_unlink(name);

    return 0
}

```

### 파이프

파이프는 두 프로세스가 통신할 수 있게 하는 전달자로서 동작한다. 파이프는 초기 UNIX 시스템에서 제공하는 IPC 기법의 하나였다. 파이프는 통상 프로세스 간에 통신하는 간단한 방법의 하나이지만 통신할 때 제약이 많다. 파이프를 구현하기 위해서는 아래의 4가지 문제를 고려해야 한다.

1. 파이프가 단, 양방향 통신을 허용하는가?
2. 양방향 통신이 허용된다면 반이중 방식인가, 전이중 방식인가? (반이중 방식은 동시에 한방향만 가능, 전이중 방식은 동시에 양방향 가능)
3. 통신하는 두 프로세스 간에 부모-자식과 같은 특정 관계가 존재해야만 하는가?
4. 파이프는 네트워크를 통하여 통신이 가능한가? 아니면 동일한 기계 안에 존재하는 두 프로세스끼리만 통신할 수 있는가?

### 일반 파이프

일반 파이프는 생산자 - 소비자 형태로 두 프로세스 간의 통신을 허용한다. 생산자는 파이프의 한 종단에 쓰고, 소비자는 다른 종단에서 읽는다. 결과적으로 일반 파이프는 한쪽으로만 데이터를 전송할 수 있으며 **오직 단방향 통신만을 가능하게 한다.** 만일 양방향 통신이 필요하다면 각각 다른 방향으로 데이터를 전송할 수 있는 **두 개**의 파이프를 사용해야 한다. UNIX 시스템에서 일반 파이프는 다음 함수를 사용하여 구축된다.

```c
pipe(int fd[])
```

이 함수는 fd[] 파일 디스크립터를 통해 접근되는 파이프를 생선한다. fd[0]은 파이프의 읽기 종단이고 fd[1]은 파이프의 쓰기 종단으로 동작한다. UNIX 파이프를 파일의 특수한 유형으로 취급한다. 따라서 파이프는 일반적인 read()와 write() 시스템 콜을 사용하여 접근될 수 있다.

일반 파이프는 파이프를 생성한 프로세스 이외에는 접근할 수 없다. 따라서 부모 프로세스가 파이프를 생성하고 fork() 시스템 콜로 생성한 자식 프로세스와 통신하기 위해 사용한다.

> 자식 프로세스는 열린 파일을 부모로부터 상속받는다는 것을 기억하라. 파이프는 특수한 유형이기 때문에 자식 프로세스는 부모로부터 파이프를 상속받는다.

아래의 그림은 fd 배열의 파일 디스크립터와 부모 및 자식 프로세스의 관계를 보여준다.

![imageProcess]({{ site.url }}{{ site.baseurl }}/assets/images/posts/image_os_nomal_pipe.png)

이 그림에서 보듯이 부모가 파이프의 쓰기 종단에 데이터를 쓰면 파이프의 읽기 종단에서 자식이 읽을 수 있다.

```c

/* include groups */

#define BUFFER_SIZE 25
#define READ_END 0
#define WRITE_END 1

int main() {
    char write_msg[BUFFER_SIZE] = "Greetings";
    char read_msg[BUFFER_SIZE];
    int fd[2];
    pid_t pid;

    if (pipe(fd) == -1) {
        fprintf(stderr, "Pipe failed");
        return 1;
    }

    pid = fork()

    if (pid < 0) {
        fprintf(stderr, "Fork failed");
        return 1;
    } 

    if (pid > 0) {
        close(fd[READ_END]);

        write(fd[WRITE_END], write_msg, strlen(write_msg) + 1);

        close(fd[WRITE_END]);
    } else {
        close(fd[WRITE_END]);

        read(fd[READ_END], read_msg, BUFFER_SIZE);
        printf("read %s", read_msg);

        close(fd[READ_END])
    }

    return 0;
}

```

위의 코드에서 보인 UNIX 프로그램에서 부모 프로세스는 파이프를 생성하고 자식 프로세스를 생성하기 위하여 fork() 시스템 콜을 호출한다. fork() 후에 일어나는 작업은 파이프를 통해 데이터가 어떻게 흘러가느냐에 따라 달라진다. 이 예제에서는 부모 프로세스가 파이프에 쓰고, 자식 프로세스가 파이프로 부터 읽는다. 부모와 자식 프로세스 모두 처음에 자신들이 사용하지 않는 파이프의 종단을 닫는 것을 주의하라.

> 위의 코드에는 이러한 작업을 하지 않지만, writer가 파이프의 종단을 닫았을 때, 파이프로부터 읽는 프로세스가 __end-of-file__ 을 탐지하는 것을 보장한다.

### 지명 파이프

지명 파이프는 양방향 통신이 가능하며, 부모 - 자식 관계도 존재하지 않으므로 일반 파이프보다 좀 더 강력한 통신 도구이다. 일단 지명 파이프가 구축되고 나면 여러 프로세스들이 이를 사용하여 통신할 수 있다. 실제 여러 예제를 보면 지명 파이프는 다수의 writer를 가진다. 추가로 통신 프로세스가 종료하더라도 지명 파이프는 계속 존재하게 된다.

지명 파이프를 UNIX에서는 FIFO라고 부른다. 일단 생성되면 지명 파이프는 파일 시스템의 보통 파일처럼 존재한다. FIFO는 mkfifo() 시스템 콜을 이용하여 생성되고 일반적인 open(), read(), write(), close() 시스템 콜로 조작되며 명시적으로 파일 시스템에서 삭제될 때까지 존재한다. FIFO가 양방향 통신을 허용하기는 하지만 반이중 전송만이 가능하다. 만약 데이터가 양방향으로 전송될 필요가 있다면, 보통 2개의 FIFO가 사용하며 통신하는 두 프로세스는 동일한 기계 내에 존재해야 한다.

> 서로 다른 기계에 존재하는 프로세스 사이의 통신이 필요하다면 소켓을 참조하자!

## 클라이언트 - 서버 환경 통신

### 소켓

소켓은 통신의 엔드포인트를 뜻한다. 두 프로세스가 네트워크상에서 통신을 하려면 양 프로세스마다 하나씩, **총 두 개의 소켓**이 필요해진다. 각 소켓은 IP 주소와 포트 번호 두 가지를 결합하여 구별한다. 일반적으로 소켓은 클라이언트 - 서버 구조를 사용한다. 서버는 지정된 포트에 클라이언트 요청 메시지가 도착하기를 기다리며, 요청이 수신되면 서버는 클라이언트 소켓으로부터 연결 요청을 수락함으로써 연결이 완성된다. Telnet, ftp, http 등의 특정 서비스를 구현하는 서버는 well-known 포트로부터 메시지를 기다린다.

> well-known 이란 전 세계적으로 사용하는 포트 번호라는 의미
> * SSH - 22
> * FTP - 21
> * HTTP - 80
>
> 1024 미만의 모든 포트는 well-known 포트로 간주되며 표준 서비스를 구현하는 데 사용된다.

클라이언트 프로세스가 연결을 요청하면 호스트 컴퓨터가 포트 번호를 부여한다. 포트 번호는 1024보다 큰 임의의 정수가 된다. 또한 모든 연결은 유일해야 하며, 호스트에 있는 다른 클라이언트 프로세스가 동일한 웹 서버와 통신을 하려면 클라이언트는 유니크한 포트 번호를 부여받게 된다. 이 행동은 모든 연결이 유일한 소켓 쌍으로 구성되는 것을 보장한다.

소켓을 이용한 통신은 분산된 프로세스 간에 널리 사용되고 효율적이기는 하지만 **소켓은 바이트 스트림만을 통신하도록 하기 때문에** 너무 낮은 수준이다. 이러한 바이트 스트림 데이터를 구조화 하여 해석하는 것은 클라이언트와 서버의 책임이 된다.

### RPC

원격 서비스와 관련한 가장 보편적인 형태 중 하나는 RPC 패러다임이다. 네트워크에 연결된 두 시스템 사이의 통신에 사용하기 위하여 함수 호출 기법을 추상화 하는 방법으로 설계되었다. 

> RPC는 IPC와 유사한 측면이 많다. 왜냐하면 IPC 기반 위에서 RPC가 만들어지기 때문이다.

여기서의 예제는 프로세스들이 서로 다른 시스템 위에서 동작하기 때문에 원격 서비스를 제공하기 위해서는 메시지 통신 기반을 사용해야 한다. IPC 방식과는 달리 RPC 통신에서 전달되는 메시지는 구조화되어 있고, 따라서 데이터의 패킷 수준을 넘어서게 된다. 각 메시지에는 원격지 포트에서 __listen__ 중인 RPC 데몬의 주소가 지정되어 있고 실행되어야 할 함수의 식별자, 그리고 그 함수에게 전달되어야 하는 매개변수가 포함된다. 그런 후에 요청된 함수가 실행되고 어떤 출력이든지 별도의 메시지를 통해 요청자에게 반환된다.

이 컨텍스트에서 포트는 단순히 메시지 패키지의 시작 부분에 포함되는 정수이다. 시스템은 일반적으로 네트워크 주소는 하나씩 가지지만 그 시스템에서 지원되는 여러 서비스를 구별하기 위해 포트를 여러 개 가질 수 있다. 원격 프로세스가 어떤 서비스를 받고자 하면 그 서비스에 대응되는 적절한 포트 주소로 메시지를 보내야 한다. 예를 들어 한 시스템이 자신의 사용자 목록을 다른 시스템에서 알고자 한다면, 관련 데몬을 port 3027과 같은 곳에 등록시켜 놓는다. 그러면 원격 시스템은 서버의 포트 3027로 RPC 메시지를 보내면 필요한 정보를 얻을 수 있다. 이 데이터는 응답 메시지 형태로 받게 된다.

RPC는 클라이언트가 원격 호스트의 함수 호출하는 것을 마치 자기 자신의 함수 호출하는 것처럼 해준다. **RPC 시스템은 클라이언트 쪽에 스텁을 제공하여 통신을 하는 데 필요한 자세한 사항들을 숨겨 준다.**

>  보통 원격 함수 마다 다른 스텁이 존재한다.

클라이언트가 원격 함수를 호출하면 RPC는 그에 대응하는 스텁을 호출하고 원격 함수가 필요로 하는 매개변수를 건네준다. 그러면 스텁이 원격 서버의 포트를 찾고 매개변수를 정돈한다. 그 후 스텁은 메시지 전달 기법을 사용하여 서버에게 메시지를 전송한다. 이에 대응되는 스텁이 서버에도 존재하여 서버 측 스텁이 메시지를 수신한 후 적절한 서버의 함수를 호출하며, 필요한 경우 반환 값들도 동일한 방식으로 되돌려 준다.

#### RPC 문제 1

파라미터 정돈은 클라이언트와 서버 기기의 데이터 표현방식의 차이를 해결한다. 컴퓨터 구조 마다 데이터 표현 방식이 다르므로 RPC 시스템은 시스템 중립적인 데이터 표현 방식을 정의한다. 이러한 표현 방식 중 하나가 XDR 이다. 클라이언트 측에서는 서버에게 데이터를 보내기 전 매개변수 정돈 작업의 일환으로 전송할 데이터를 기종 중립적인 XDR 형태로 변경해서 보낸다. 수신측 시스템에서는 XDR 데이터를 받으면 매개변수를 풀어내면서 자기 기종의 형태로 데이터를 변경 후 서버에게 넘겨준다. 또 다른 중요한 문제는 호출의 의미에 관한 것이다. 지역 함수 호출의 경우 극단적인 경우에만 실패하지만 RPC의 경우 네트워크 오류 때문에 실패할 수도 있고, 메시지가 중복되어 호출이 여러 번 실행될 수도 있다. 이 문제를 해결하는 방법은 운영체제의 메시지가 최대 한 번 실행되는 것이 아니라 **정확히 한번** 처리되도록 보장하게 하는 것이다. 대부분의 지역 함수 호출은 정확히 한 번의 기능성을 가지고 있으나 이를 구현하는 것은 어렵다.

#### RPC 문제 2

우선 **최대 한 번**을 고려하자. 이 의미는 각 메시지에 타임스탬프를 매기는 것으로 보장할 수 있다. 서버는 이미 처리한 모든 메시지의 타임스탬프 기록을 가지거나 중복된 메시지를 검사해 낼 수 있을 만큼의 기록을 가져야 한다. __기록에 보관된 타임스탬프를 가진 메시지가 도착하면 그 메시지는 무시된다.__ 이렇게 처리하면 클라이언트는 한 번 이상 메시지를 보낼 수 있고 메시지에 대한 실행이 단 한 번 실행된다는 것을 보장받을 수 있다. **정확히 한 번**의 의미를 가지려면 서버가 요청을 받지 못하는 위험을 제거할 필요가 있다. 이를 완수하려면 서버는 위에서 설명한 **최대 한 번** 프로토콜을 구현하고 RPC 요청이 수신되었고 실행됐다는 응답 메시지를 보내야만 한다. 이 응답 메시지는 네트워킹에서 일반적이다. 클라이언트는 해당 호출에 대한 응답을 받을 때까지 주기적으로 각 RPC 호출을 재전송 해야 한다.

#### RPC 문제 3

또 하나 다루어야 할 중요한 문제는 클라이언트와 서버 간의 통신 문제이다. 일반적인 함수 호출의 경우, 바인딩이라는 작업이 링킹, 적재, 실행 시점에 행해진다. 이때 **함수의 이름이 함수의 메모리 주소로 변환된다.** 이와 마찬가지로 RPC도 클라이언트와 서버의 포트를 바인딩 해야 하는데, 클라이언트는 서버의 포트 번호를 어떻게 알 수 있는가? 두 시스템에는 모두 상대방에 대한 완전한 정보가 없다. 이를 위해 두 가지 방법이 사용된다. 첫 번째 방법은 고정된 포트 주소 형태로 미리 정해놓는 방법이다. 컴파일 할 때 RPC에 이 고정된 포트 번호를 준다. 컴파일 되고 나면 그 후에는 서버가 그 포트 번호를 임의로 바꿀 수 없다. 두 번째는 랑데부 방식에 의해 동적으로 바인딩 하는 방법이다. 보통 운영체제는 미리 정해져 있는 고정 RPC 포트를 통해 랑데부용 데몬을 제공한다. 그러면 클라이언트가 자신이 실행하기를 원하는 RPC의 이름을 담고 있는 메시지를 랑데부 데몬에 보내서, RPC 이름에 대응하는 포트 번호가 무엇인지 알려달라고 요청한다. 그러면 포트 번호가 클라이언트에게 반환되고, 클라이언트는 그 포트 번호로 RPC 요청을 계속 보낸다. 이 방식은 통신 초기에 오버헤드가 좀 들기는 하지만 첫 번째 방식보다 유연하다.

RPC는 분산 파일 시스템을 구현하는데 유용하다. DFS는 몇 개의 RPC 데몬과 클라이언트로 구현할 수 있다. 메시지가 원격지 DFS 서버 포트로 보내지고 이 서버는 파일 조작을 실행해 준다. 메시지는 실행할 디스크 연산을 포함한다. 이 디스크 연산은 아마도 보통의 파일 관련 연산에 해당하는 함수등일 것이다. DFS는 이 연산 결과를 클라이언트에게 반환 메시지로 보낸다. 에를 들면, 어떤 메시지는 파일 전체를 보내라는 것일 수도 있고, 어떤 메시지는 몇 개의 블록만 보내라는 것이 될 수 있다. 후자의 경우는 그것을 몇 차례 반복하면 파일 전체를 보내게 될 수도 있다.